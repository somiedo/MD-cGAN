{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e052e5",
   "metadata": {},
   "source": [
    "# MD-cGAN y cálculo FID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4f29cb",
   "metadata": {},
   "source": [
    "Para poder ejecutar el algoritmo en ***Kaggle*** y poder hacer uso de GPU insertamos el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAGGLE\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b98101b",
   "metadata": {},
   "source": [
    "## Implementación de la red MD-cGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fac0cf",
   "metadata": {},
   "source": [
    "### Paquetes necesarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c0bac0",
   "metadata": {},
   "source": [
    "Importamos los paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c26684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos paquetes necesarios\n",
    "from tensorflow import keras\n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Average\n",
    "from tensorflow.keras.layers import Minimum\n",
    "from tensorflow.keras.layers import Maximum\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299d0880",
   "metadata": {},
   "source": [
    "### Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280325ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos las etiquetas\n",
    "labels = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# cargamos los datos (train)\n",
    "X_train = []\n",
    "y_train = []\n",
    "y_train_new = []\n",
    "\n",
    "# tamaño de las imágenes 150x150\n",
    "image_size=112\n",
    "\n",
    "for i in labels:\n",
    "    folderPath = os.path.join('../input/brain-tumor-mri-dataset/', 'Training', i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        image = cv2.imread(os.path.join(folderPath, j))\n",
    "        image = cv2.resize(image, (image_size, image_size))\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        X_train.append(image)\n",
    "        y_train.append(i)\n",
    "\n",
    "# convertimos en un array\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# convertir y_train en entero\n",
    "# glioma -> 0, meningioma -> 1, notumor -> 2, pituitary  -> 3\n",
    "for i in y_train:\n",
    "    y_train_new.append(labels.index(i))\n",
    "    \n",
    "# mezclamos los datos\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=1970)    \n",
    "dataset_bio = (X_train, np.asarray(y_train_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f78569",
   "metadata": {},
   "source": [
    "Una vez cargados los datos podemos visualizar algunos ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizamos algunos ejemplos\n",
    "grid_width = 4\n",
    "grid_height = 4\n",
    "f, ax = plt.subplots(grid_width, grid_height)\n",
    "f.set_size_inches(8, 8)\n",
    "\n",
    "img_idx = 0\n",
    "for i in range(0, grid_width):\n",
    "    for j in range(0, grid_height):\n",
    "        ax[i][j].axis('off')\n",
    "        ax[i][j].set_title(y_train[img_idx])\n",
    "        ax[i][j].imshow(X_train[img_idx])\n",
    "        img_idx += 1\n",
    "\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.2, hspace=0.40)\n",
    "\n",
    "# guardamos el fichero de imágenes\n",
    "pyplot.savefig(\"img_real.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a932aa7",
   "metadata": {},
   "source": [
    "### Modelo discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28444e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el modelo discriminador\n",
    "def define_discriminator(in_shape=(112,112,3), n_classes=4):\n",
    "    # etiquetas de entrada\n",
    "    in_label = Input(shape=(1,))\n",
    "    # incrustamos las etiquetas\n",
    "    li = Embedding(n_classes, 50)(in_label)\n",
    "    # escalamos al tamaño de las imágenes\n",
    "    n_nodes = in_shape[0] * in_shape[1]\n",
    "    li = Dense(n_nodes)(li)\n",
    "    # remodelamos un canal adicional\n",
    "    li = Reshape((in_shape[0], in_shape[1], 1))(li)\n",
    "    # entrada de imágenes\n",
    "    in_image = Input(shape=in_shape)\n",
    "    # concatenamos imagen y etiqueta\n",
    "    merge = Concatenate()([in_image, li])\n",
    "    # reducción por convolución 112x112 -> 56x56\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same', input_shape=in_shape)(merge)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    # reducción por convolución 56x56 -> 28x28\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    # reducción por convolución 28x28 -> 14x14\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    # reducción por convolución 14x14 -> 7x7\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    # aplanado\n",
    "    fe = Flatten()(fe)\n",
    "    # dropout\n",
    "    fe = Dropout(0.4)(fe)\n",
    "    # output\n",
    "    out_layer = Dense(1, activation='sigmoid')(fe)\n",
    "    # definimos el modelo\n",
    "    model = Model([in_image, in_label], out_layer)\n",
    "    # compilamos el modelo\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace1d42",
   "metadata": {},
   "source": [
    "Podemos ver la estructura del modelo discriminador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4636dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = define_discriminator()\n",
    "# summarize the model\n",
    "model.summary()\n",
    "# plot the model\n",
    "plot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e0cfd",
   "metadata": {},
   "source": [
    "### Modelo generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3875d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el modelo generador\n",
    "# proporcionamos el espacio latente y el número de clases\n",
    "def define_generator(latent_dim, n_classes=4):\n",
    "    # etiquetas de entrada\n",
    "    in_label = Input(shape=(1,))\n",
    "    # incrustamos las etiquetas\n",
    "    li = Embedding(n_classes, 50)(in_label)\n",
    "    # multiplicación\n",
    "    n_nodes = 7 * 7\n",
    "    li = Dense(n_nodes)(li)\n",
    "    # remodelamos un canal adicional\n",
    "    li = Reshape((7, 7, 1))(li)\n",
    "    # entrada de imágenes\n",
    "    in_lat = Input(shape=(latent_dim,))\n",
    "    # base de la imagen 7x7\n",
    "    n_nodes = 128 * 7 * 7\n",
    "    gen = Dense(n_nodes)(in_lat)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((7, 7, 128))(gen)\n",
    "    # concatenamos imagen y etiqueta\n",
    "    merge = Concatenate()([gen, li])\n",
    "    # aumentamos por convolución 7x7 -> 14x14\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    # aumentamos por convolución 14x14 -> 28x28\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    # aumentamos por convolución 28x28 -> 56x56\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    # aumentamos por convolución 56x56 -> 112x112\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    \n",
    "    # output\n",
    "    out_layer = Conv2D(3, (7,7), activation='tanh', padding='same')(gen)\n",
    "    # definimos el modelo (no lo compilamos)\n",
    "    model = Model([in_lat, in_label], out_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0768fca4",
   "metadata": {},
   "source": [
    "También podemos ver la estructura del modelo generador creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31af3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = define_generator(latent_dim=100, n_classes=4)\n",
    "# summarize the model\n",
    "model.summary()\n",
    "# plot the model\n",
    "plot_model(model, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e30aba",
   "metadata": {},
   "source": [
    "### Modelo GAN combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d645c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el modelo combinado de generador-discriminador, para actualizar el generador\n",
    "def define_gan(g_model, d_model, num_d):\n",
    "    y = []\n",
    "    # congelamos los modelos discriminadores para que no entrenen\n",
    "    for n_d in range(num_d):\n",
    "        d_model[n_d].trainable = False\n",
    "    # obtenemos la entrada de ruido y etiquetas del modelo generador\n",
    "    gen_noise, gen_label = g_model.input\n",
    "    # obtenemos la imagen de salida del modelo generador\n",
    "    gen_output = g_model.output\n",
    "    # conectamos la imagen y la etiqueta del generador como entradas del discriminador\n",
    "    #gan_output = d_model([gen_output, gen_label])\n",
    "    if num_d==1:\n",
    "        gan_output = d_model[0]([gen_output, gen_label])\n",
    "    else:\n",
    "        for n_d in range(num_d):\n",
    "            y.append(d_model[n_d]([gen_output, gen_label]))\n",
    "            # definimos el cálculo (Average, Maximum ó Minimum)\n",
    "            gan_output = Maximum()(y)\n",
    "    # definimos el modelo combinado gan\n",
    "    model = Model([gen_noise, gen_label], gan_output)\n",
    "    # compilamos el modelo\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69548b7c",
   "metadata": {},
   "source": [
    "### Cargamos las imágenes reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f53fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos las imágenes del brain-tumor-mri\n",
    "def load_real_samples():\n",
    "    # cargamos los datos de entrenamiento\n",
    "    #(trainX, trainy), (_, _) = load_data()\n",
    "    (trainX, trainy) = dataset_bio\n",
    "    #trainX, trainy = X_train, y_train\n",
    "    # añadimos un canal -> 3D para la etiqueta de clase\n",
    "    X = expand_dims(trainX, axis=-1)\n",
    "    # convertimos de entero a flotante\n",
    "    X = X.astype('float32')\n",
    "    # escalamos [0, 255] -> [-1, 1]\n",
    "    X = (X - 127.5) / 127.5\n",
    "    return [X, trainy]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c794f",
   "metadata": {},
   "source": [
    "### Seleccionamos aleatoriamente las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed328ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionamos aleatoriamente un grupo de imágenes reales\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # dividimos en imágenes y etiquetas\n",
    "    images, labels = dataset\n",
    "    # selección aleatoria de índices\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "    # selección aleatoria de imágenes y etiquetas\n",
    "    X, labels = images[ix], labels[ix]\n",
    "    # generamos las etiquetas de clase 1 -> real (0 -> fake)\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346a9f2",
   "metadata": {},
   "source": [
    "### Puntos del espacio latente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e12f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos puntos en el espacio latente como entrada para el generador\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=4):\n",
    "    # generamos aleatoriamente puntos\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # redimensionamos\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    # generamos las etiquetas\n",
    "    labels = randint(0, n_classes, n_samples)\n",
    "    return [z_input, labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e6ee4d",
   "metadata": {},
   "source": [
    "### Generamos imágenes falsas (fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86fa44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizamos el generador para crear imágenes falsas\n",
    "# con etiquetas de clase (0 -> fake)\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    # generamos puntos en el espacio latente\n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predicción\n",
    "    images = g_model.predict([z_input, labels_input])\n",
    "    # generamos las etiquetas de clase 0 -> fake (1 -> real)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return [images, labels_input], y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c6f2b4",
   "metadata": {},
   "source": [
    "### Guardamos grupo de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac42337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardamos un plot con las imágenes generadas (4x4)\n",
    "def save_plot(examples, epoch, n=4):\n",
    "    # creamos el plot\n",
    "    for i in range(n * n):\n",
    "        # subplot\n",
    "        pyplot.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot\n",
    "        pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
    "    # guardamos el fichero de imágenes\n",
    "    filename = 'gen_1D_plot_e%03d.png' % (epoch+1)\n",
    "    pyplot.savefig(filename)\n",
    "pyplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e85898",
   "metadata": {},
   "source": [
    "### Evaluamos el modelo discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1efcd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluamos el modelo discriminador, generamos imágenes y guardamos el modelo generador\n",
    "def summarize_performance(epoch, g_model, d_model, num_d, dataset, latent_dim, n_samples=100):\n",
    "    acc_real = []\n",
    "    acc_fake = []\n",
    "    #tot_acc_real = []\n",
    "    #tot_acc_fake = []\n",
    "    #tot_epoch = []\n",
    "    # muestras de imágenes reales\n",
    "    [X_real, labels_real], y_real = generate_real_samples(dataset, n_samples)\n",
    "    # muestras de imágenes fake\n",
    "    [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # evaluamos el discriminador con las muestras reales y falsas\n",
    "    for n_d in range(num_d):\n",
    "        _, acc_real.append(d_model[n_d].evaluate([X_real, labels_real], y_real, verbose=0))\n",
    "        _, acc_fake.append(d_model[n_d].evaluate([X_fake, labels_fake], y_fake, verbose=0))\n",
    "        # rendimiento del discriminador\n",
    "        print('>Accuracy real_%d: %.0f%%, fake_%d: %.0f%%' % (n_d+1, acc_real[n_d][-1]*100, n_d+1, acc_fake[n_d][-1]*100))\n",
    "        # guardamos el rendimiento del discriminador\n",
    "        #tot_acc_real.append(acc_real[n_d]*100)\n",
    "        #tot_acc_fake.append(acc_fake[n_d]*100)\n",
    "    #tot_epoch.append(epoch +1)\n",
    "    # muestras de imágenes fake\n",
    "    latent_points, labels = generate_latent_points(100, 100)\n",
    "    # etiquetas\n",
    "    labels = asarray([x for _ in range(25) for x in range(4)])\n",
    "    # generamos las imágenes fake\n",
    "    X  = g_model.predict([latent_points, labels])\n",
    "    # escalamos [-1, 1] -> [0, 1]\n",
    "    X = (X + 1) / 2.0\n",
    "    # salvamos el gráfico\n",
    "    save_plot(X, epoch)\n",
    "\n",
    "    # guardamos el modelo generador\n",
    "    filename = 'gen_model_1D_%03d.h5' % (epoch + 1)\n",
    "    g_model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61b9d58",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo generador y discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el modelo generador y discriminador\n",
    "def train(g_model, d_model, num_d, gan_model, dataset, latent_dim, n_epochs, n_batch):\n",
    "    \n",
    "\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # recorremos las épocas\n",
    "    for i in range(n_epochs):\n",
    "        # recorremos los lotes definidos por época\n",
    "        for j in range(bat_per_epo):\n",
    "            # muestras aleatorias de imágenes reales\n",
    "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "            # muestras de imágenes fake\n",
    "            [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # actualizamos los pesos del modelo discriminador\n",
    "            d_loss_real = []\n",
    "            d_loss_fake = []\n",
    "            for n_d in range(num_d):\n",
    "                #d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "                #d_loss_real.append(d_model[n_d].train_on_batch([X_real, labels_real], y_real))\n",
    "                #d_loss_fake.append(d_model[n_d].train_on_batch([X_fake, labels_fake], y_fake))\n",
    "                d_loss_real, _ = d_model[n_d].train_on_batch([X_real, labels_real], y_real)\n",
    "                d_loss_fake, _ = d_model[n_d].train_on_batch([X_fake, labels_fake], y_fake)\n",
    "                \n",
    "                \n",
    "            # preparamos puntos en el espacio latente como entrada para el modelo generador\n",
    "            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "            # creamos etiquetas falsas para las muestras fake (en lugar de 0)\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            # actualizamos el modelo generador mediante el error del discriminador\n",
    "            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "            \n",
    "            # pérdidas del lote\n",
    "            #for n_d in range(num_d):\n",
    "            #    print('>%d, %d/%d, d_real_%d=%.3f, d_fake%d=%.3f g=%.3f' %\n",
    "            #    (i+1, j+1, bat_per_epo, n_d+1, d_loss_real[n_d][-1], n_d+1, d_loss_fake[n_d][-1], g_loss))\n",
    "\n",
    "        # evaluamos el rendimiento del modelo cada 10 épocas\n",
    "        if (i+1) % 10 == 0:\n",
    "            summarize_performance(i, g_model, d_model, num_d, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aa9976",
   "metadata": {},
   "source": [
    "### Parametros de la GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae9d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tamaño imagen\n",
    "image_shape = (112,112,3)\n",
    "\n",
    "# épocas\n",
    "n_epochs = 200\n",
    "# lote\n",
    "n_batch = 128\n",
    "# tamaño del espacio latente (100, 10, 50, 500)\n",
    "latent_dim = 100\n",
    "# num discriminators\n",
    "num_d = 1\n",
    "\n",
    "# creamos los modelos discriminadores\n",
    "d_model = []\n",
    "for n_d in range(num_d):\n",
    "     d_model.append(define_discriminator())\n",
    "    \n",
    "# creamos el modelo generador\n",
    "g_model = define_generator(latent_dim)\n",
    "# creamos el modelo combinado\n",
    "gan_model = define_gan(g_model, d_model, num_d)\n",
    "# cargamos imágenes reales\n",
    "dataset = load_real_samples()\n",
    "# entrenamos la red\n",
    "train(g_model, d_model, num_d, gan_model, dataset, latent_dim, n_epochs, n_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed95aa",
   "metadata": {},
   "source": [
    "### Visualizamos algunas imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8984e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos el modelo\n",
    "model_guardado = load_model('gen_model_180.h5')\n",
    "# generamos espacio latente\n",
    "latent_points, labels = generate_latent_points(100, 16)\n",
    "# especificamos etiquetas\n",
    "labels = asarray([x for _ in range(4) for x in range(4)])\n",
    "\n",
    "# generamos imágenes\n",
    "X  = model_guardado.predict([latent_points, labels])\n",
    "\n",
    "# escalamos\n",
    "X = (X + 1) / 2.0\n",
    "\n",
    "# visualizamos algunos ejemplos\n",
    "grid_width = 4\n",
    "grid_height = 4\n",
    "f, ax = plt.subplots(grid_width, grid_height)\n",
    "f.set_size_inches(8, 8)\n",
    "\n",
    "labels = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "img_idx = 0\n",
    "for i in range(0, grid_width):    \n",
    "    for j in range(0, grid_height):\n",
    "        ax[i][j].axis('off')\n",
    "        ax[i][j].set_title(labels[j])\n",
    "        ax[i][j].imshow(X[img_idx])\n",
    "        img_idx += 1\n",
    "\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.2, hspace=0.40)\n",
    "\n",
    "# guardamos el fichero de imágenes\n",
    "pyplot.savefig(\"img_fake_1D_180.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62adae9a",
   "metadata": {},
   "source": [
    "## Cálculo del FID y gráfico generado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed54ac",
   "metadata": {},
   "source": [
    "Cargamos paquetes necesarios por si no los hubiéramos cargado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9414607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos imágenes con modelo generador\n",
    "# Importamos paquetes necesarios\n",
    "import numpy\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy import asarray\n",
    "from numpy.random import shuffle\n",
    "from scipy.linalg import sqrtm\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.datasets.mnist import load_data\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf891bb5",
   "metadata": {},
   "source": [
    "### Escalado de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ed462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# escalamos las imágenes\n",
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # redimensionamos con la interpolación del vecino más cercano\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        # guardamos\n",
    "        images_list.append(new_image)\n",
    "    return asarray(images_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1471435",
   "metadata": {},
   "source": [
    "### Cálculo del FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca3bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cálculo del FID\n",
    "def calculate_fid(model, images1, images2):\n",
    "    # predicción del modelo InceptionV3\n",
    "    act1 = model.predict(images1)\n",
    "    act2 = model.predict(images2)\n",
    "    # calculamos la media y covarianza\n",
    "    mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
    "    # calculamos la suma de los cuadrados de la difencia de medias\n",
    "    ssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
    "    # calculamos la raiz cuadrada del producto de las covarianzas\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    # comprobamos y corregimos los números imaginarios de la raiz\n",
    "    if iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculamos el FID\n",
    "    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b26a792",
   "metadata": {},
   "source": [
    "### Preparamos el modelo *Inception v3* (discriminador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparamos el modelo inception v3 (discriminador)\n",
    "model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd5d6d2",
   "metadata": {},
   "source": [
    "### Parametrizamos el modelo generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd58af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros\n",
    "n_paquetes = 100\n",
    "n_classes = 4\n",
    "num_imag = n_paquetes * n_classes\n",
    "\n",
    "# generamos espacio latente\n",
    "latent_points, labels = generate_latent_points(100, num_imag, n_classes)\n",
    "\n",
    "# etiquetas\n",
    "labels = asarray([x for _ in range(n_paquetes) for x in range(n_classes)])\n",
    "\n",
    "# cargamos el modelo\n",
    "fid_epoch = []\n",
    "epoch = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecd52c1",
   "metadata": {},
   "source": [
    "### Generamos pool de imágenes reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0477696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos imágenes reales\n",
    "dataset = load_real_samples()\n",
    "n_samples = 400\n",
    "[X_real, labels_real], y_real = generate_real_samples(dataset, n_samples)\n",
    "X_real = X_real.astype('float32')\n",
    "\n",
    "#escalamos las imágenes\n",
    "X_real = scale_images(X_real, (299,299,3))\n",
    "\n",
    "# preprocesamos imágenes\n",
    "X_real = preprocess_input(X_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94d679",
   "metadata": {},
   "source": [
    "### Calculamos el FID para los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3cd4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FID para los modelos seleccionados\n",
    "for i in range(20):\n",
    "    model_guardado = 'gen_model_1D_%03d.h5' % ((i + 1) * 10)\n",
    "    model_guardado = load_model(model_guardado)\n",
    "    \n",
    "    # generamos imágenes\n",
    "    X_fake = model_guardado.predict([latent_points, labels])\n",
    "    X_fake = X_fake.astype('float32')\n",
    "    # escalamos las imágenes\n",
    "    X_fake = scale_images(X_fake, (299,299,3))\n",
    "    print('Scaled', X_real.shape, X_fake.shape)\n",
    "    # preprocesamos imágenes\n",
    "    X_fake = preprocess_input(X_fake)\n",
    "    # calculamos el fid\n",
    "    fid = calculate_fid(model, X_real, X_fake)\n",
    "    fid_epoch.append(fid)\n",
    "    epoch.append((i+1) * 10)\n",
    "    print('FID: %.3f' % fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bd06d7",
   "metadata": {},
   "source": [
    "### Gráfico del FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c233d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "x = epoch\n",
    "y = fid_epoch\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.clf()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.clear()\n",
    "ax.plot(x, y,  marker='D')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('fid')\n",
    "ax.set_title('FID por épocas')\n",
    "fig.show()\n",
    "\n",
    "#fig.savefig(\"FID.png\", bbox_inches='tight')\n",
    "fig.savefig(\"FID 1D 200E.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665fc2d",
   "metadata": {},
   "source": [
    "Podemos obtener los FID para las épocas calculadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b031c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2bc907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiEntorno",
   "language": "python",
   "name": "mientorno"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
