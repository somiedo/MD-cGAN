{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-05-22T09:45:15.713681Z","iopub.status.busy":"2023-05-22T09:45:15.713331Z","iopub.status.idle":"2023-05-22T09:45:15.717852Z","shell.execute_reply":"2023-05-22T09:45:15.717093Z","shell.execute_reply.started":"2023-05-22T09:45:15.713653Z"}},"source":["# MD-cGAN"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Kaggle environment"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Data reading"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.utils import shuffle\n","\n","# Define the labels\n","labels = ['glioma', 'meningioma', 'notumor', 'pituitary']\n","\n","# Load the data (train)\n","X_train = []\n","y_train = []\n","y_train_new = []\n","\n","# Image size: 112x112\n","image_size = 112\n","\n","for label in labels:\n","    folder_path = os.path.join('../input/brain-tumor-mri-dataset/', 'Training', label)\n","    for filename in tqdm(os.listdir(folder_path)):\n","        image = cv2.imread(os.path.join(folder_path, filename))\n","        image = cv2.resize(image, (image_size, image_size))\n","        # Convert image to grayscale if needed\n","        # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","        X_train.append(image)\n","        y_train.append(label)\n","\n","# Convert lists to arrays\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n","\n","# Convert y_train to integers\n","# glioma -> 0, meningioma -> 1, notumor -> 2, pituitary -> 3\n","for label in y_train:\n","    y_train_new.append(labels.index(label))\n","\n","# Shuffle the data\n","X_train, y_train_new = shuffle(X_train, y_train_new, random_state=1970)\n","\n","# Create the dataset\n","dataset_bio = (X_train, np.asarray(y_train_new))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Define the grid size for visualization\n","grid_width = 4\n","grid_height = 4\n","\n","# Create subplots\n","fig, axes = plt.subplots(grid_width, grid_height)\n","fig.set_size_inches(8, 8)\n","\n","img_idx = 0\n","for i in range(grid_width):\n","    for j in range(grid_height):\n","        # Turn off axis and set title\n","        axes[i, j].axis('off')\n","        axes[i, j].set_title(y_train[img_idx])\n","        \n","        # Display the image\n","        axes[i, j].imshow(X_train[img_idx])\n","        \n","        img_idx += 1\n","\n","# Adjust the spacing between subplots\n","plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.2, hspace=0.4)\n","\n","# Save the image file\n","plt.savefig(\"img_real.png\", bbox_inches=\"tight\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Discriminator model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, Dense, Reshape, Concatenate, Conv2D, LeakyReLU, Flatten, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","def define_discriminator(in_shape=(112, 112, 3), n_classes=4):\n","    # Input for labels\n","    in_label = Input(shape=(1,))\n","    # Embed the labels\n","    embedded_labels = Embedding(n_classes, 50)(in_label)\n","    # Scale to the size of images\n","    n_nodes = in_shape[0] * in_shape[1]\n","    embedded_labels = Dense(n_nodes)(embedded_labels)\n","    # Reshape to add an additional channel\n","    embedded_labels = Reshape((in_shape[0], in_shape[1], 1))(embedded_labels)\n","    \n","    # Input for images\n","    in_image = Input(shape=in_shape)\n","    # Concatenate image and label\n","    merged = Concatenate()([in_image, embedded_labels])\n","    \n","    # Convolutional layers for downscaling\n","    fe = Conv2D(128, (3, 3), strides=(2, 2), padding='same', input_shape=in_shape)(merged)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    \n","    fe = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(fe)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    \n","    fe = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(fe)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    \n","    fe = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(fe)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    \n","    # Flatten the feature map\n","    fe = Flatten()(fe)\n","    \n","    # Apply dropout\n","    fe = Dropout(0.4)(fe)\n","    \n","    # Output layer\n","    out_layer = Dense(1, activation='sigmoid')(fe)\n","    \n","    # Define the model\n","    model = Model([in_image, in_label], out_layer)\n","    \n","    # Compile the model\n","    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    \n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.utils import plot_model\n","\n","# Define the model\n","model = define_discriminator()\n","\n","# Summarize the model\n","model.summary()\n","\n","# Plot the model\n","plot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Generator model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.layers import Conv2DTranspose\n","\n","# Define the generator model\n","# Provide the latent space dimension and number of classes\n","def define_generator(latent_dim, n_classes=4):\n","    # Input for labels\n","    in_label = Input(shape=(1,))\n","    # Embedding for labels\n","    li = Embedding(n_classes, 50)(in_label)\n","    # Multiplication\n","    n_nodes = 7 * 7\n","    li = Dense(n_nodes)(li)\n","    # Reshape to additional channel\n","    li = Reshape((7, 7, 1))(li)\n","    # Input for latent space\n","    in_lat = Input(shape=(latent_dim,))\n","    # Base of the image (7x7)\n","    n_nodes = 128 * 7 * 7\n","    gen = Dense(n_nodes)(in_lat)\n","    gen = LeakyReLU(alpha=0.2)(gen)\n","    gen = Reshape((7, 7, 128))(gen)\n","    # Concatenate image and label\n","    merge = Concatenate()([gen, li])\n","    # Upsampling by transpose convolution (7x7 -> 14x14)\n","    gen = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(merge)\n","    gen = LeakyReLU(alpha=0.2)(gen)\n","    # Upsampling by transpose convolution (14x14 -> 28x28)\n","    gen = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(gen)\n","    gen = LeakyReLU(alpha=0.2)(gen)\n","    # Upsampling by transpose convolution (28x28 -> 56x56)\n","    gen = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(gen)\n","    gen = LeakyReLU(alpha=0.2)(gen)\n","    # Upsampling by transpose convolution (56x56 -> 112x112)\n","    gen = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(gen)\n","    gen = LeakyReLU(alpha=0.2)(gen)\n","    \n","    # Output\n","    out_layer = Conv2D(3, (7, 7), activation='tanh', padding='same')(gen)\n","    # Define the model (not compiled)\n","    model = Model([in_lat, in_label], out_layer)\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define the model\n","model = define_generator(latent_dim=100, n_classes=4)\n","# Summarize the model\n","model.summary()\n","# Plot the model\n","plot_model(model, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Combined generator-discriminator model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Calculate Median\n","import tensorflow_probability as tfp\n","# Calculate Mean, Maximum and Minimum\n","from tensorflow.math import reduce_mean, reduce_max, reduce_min\n","\n","# Calculate Mean, Maximum and Minimum\n","from tensorflow.keras.layers import Average\n","from tensorflow.keras.layers import Minimum\n","from tensorflow.keras.layers import Maximum\n","\n","\n","# Define the combined generator-discriminator model for updating the generator\n","def define_gan(g_model, d_model, num_d, parameter):\n","    y = []\n","    # Freeze the discriminator models so they don't train\n","    for n_d in range(num_d):\n","        d_model[n_d].trainable = False\n","    # Get the noise input and label from the generator model\n","    gen_noise, gen_label = g_model.input\n","    # Get the output image from the generator model\n","    gen_output = g_model.output\n","    # Connect the generator's image and label as inputs to the discriminator\n","    if num_d == 1:\n","        gan_output = d_model[0]([gen_output, gen_label])\n","    else:\n","        for n_d in range(num_d):\n","            y.append(d_model[n_d]([gen_output, gen_label]))\n","        \n","\n","        # Define the calculation (Mean, Maximum, Minimum or Median)\n","        if parameter == \"Mean\":\n","            #gan_output = Average()(y)\n","            gan_output = reduce_mean(y)\n","        elif parameter == \"Maximum\":\n","            #gan_output = reduce_max(y)\n","            gan_output = Maximum()(y)\n","        elif parameter == \"Minimum\":\n","            #gan_output = reduce_min(y)\n","            gan_output = Minimum()(y)\n","        elif parameter == \"Median\":\n","            gan_output = tfp.stats.percentile(y, q=50, interpolation='midpoint')\n","        else:\n","            print(\"Parámetro estadístico no válido\") \n","        \n","    # Define the combined GAN model\n","    model = Model([gen_noise, gen_label], gan_output)\n","    # Compile the model\n","    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy', optimizer=opt)\n","    return model\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load samples"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load the brain tumor MRI images\n","def load_real_samples():\n","    # Load the training data\n","    (trainX, trainy) = dataset_bio\n","\n","    # Add an additional channel for the class label (3D)\n","    X = expand_dims(trainX, axis=-1)\n","\n","    # Convert from integer to float\n","    X = X.astype('float32')\n","\n","    # Scale the pixel values from [0, 255] to [-1, 1]\n","    X = (X - 127.5) / 127.5\n","\n","    return [X, trainy]\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Define modules"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from numpy import expand_dims, ones, zeros, asarray\n","from numpy.random import randint, randn\n","from matplotlib import pyplot\n","\n","\n","# Select a random group of real images\n","def generate_real_samples(dataset, n_samples):\n","    # Split images and labels\n","    images, labels = dataset\n","\n","    # Randomly select indices\n","    ix = randint(0, images.shape[0], n_samples)\n","\n","    # Randomly select images and labels\n","    X, labels = images[ix], labels[ix]\n","\n","    # Generate class labels (1 for real, 0 for fake)\n","    y = ones((n_samples, 1))\n","    return [X, labels], y\n","\n","\n","# Generate points in the latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples, n_classes=4):\n","    # Generate random points\n","    x_input = randn(latent_dim * n_samples)\n","\n","    # Reshape points\n","    z_input = x_input.reshape(n_samples, latent_dim)\n","\n","    # Generate labels\n","    labels = randint(0, n_classes, n_samples)\n","    return [z_input, labels]\n","\n","\n","# Use the generator to generate fake samples with class labels (0 for fake)\n","def generate_fake_samples(g_model, latent_dim, n_samples):\n","    # Generate points in the latent space\n","    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n","\n","    # Generate predictions\n","    images = g_model.predict([z_input, labels_input])\n","\n","    # Generate class labels (0 for fake, 1 for real)\n","    y = zeros((n_samples, 1))\n","    return [images, labels_input], y\n","\n","\n","# Save a plot of generated images (4x4 grid)\n","def save_plot(examples, epoch, num_d, parameter, n=4):\n","    for i in range(n * n):\n","        pyplot.subplot(n, n, 1 + i)\n","        pyplot.axis('off')\n","        pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n","    filename = 'plot_%s_%dD_e%03d.png' % (parameter, num_d, epoch + 1)\n","    pyplot.savefig(filename)\n","    pyplot.close()\n","\n","\n","# Evaluate the discriminator model, generate images, and save the generator model\n","def summarize_performance(epoch, g_model, d_model, num_d, dataset, latent_dim, parameter, n_samples=100):\n","    acc_real = []\n","    acc_fake = []\n","\n","    [X_real, labels_real], y_real = generate_real_samples(dataset, n_samples)\n","    [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n","\n","    for n_d in range(num_d):\n","        _, acc_real.append(d_model[n_d].evaluate([X_real, labels_real], y_real, verbose=0))\n","        _, acc_fake.append(d_model[n_d].evaluate([X_fake, labels_fake], y_fake, verbose=0))\n","        print('>Accuracy real_%d: %.0f%%, fake_%d: %.0f%%' % (n_d + 1, acc_real[n_d][-1] * 100, n_d + 1,\n","                                                               acc_fake[n_d][-1] * 100))\n","\n","    latent_points, labels = generate_latent_points(100, 100)\n","    labels = asarray([x for _ in range(25) for x in range(4)])\n","    X = g_model.predict([latent_points, labels])\n","    X = (X + 1) / 2.0\n","    save_plot(X, epoch, num_d, parameter, n=4)\n","\n","    filename = 'mod_%s_%dD_%03d.h5' % (parameter, num_d, epoch + 1)\n","    g_model.save(filename)\n","\n","\n","# Train the generator and discriminator models\n","def train(g_model, d_model, num_d, gan_model, dataset, latent_dim, n_epochs, n_batch, parameter):\n","    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n","    half_batch = int(n_batch / 2)\n","    \n","    for i in range(n_epochs):\n","        for j in range(bat_per_epo):\n","            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n","            [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","\n","            d_loss_real = []\n","            d_loss_fake = []\n","            for n_d in range(num_d):\n","                d_loss_real, _ = d_model[n_d].train_on_batch([X_real, labels_real], y_real)\n","                d_loss_fake, _ = d_model[n_d].train_on_batch([X_fake, labels_fake], y_fake)\n","\n","            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n","            y_gan = ones((n_batch, 1))\n","            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n","\n","        if (i + 1) % 10 == 0:\n","            summarize_performance(i, g_model, d_model, num_d, dataset, latent_dim, parameter, n_samples=100)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":false,"trusted":true},"outputs":[],"source":["import time\n","\n","# Set image shape\n","image_shape = (112, 112, 3)\n","\n","# Number of epochs\n","n_epochs = 200\n","\n","# Batch size\n","n_batch = 128\n","\n","# Size of the latent space (100, 10, 50, 500)\n","latent_dim = 100\n","\n","# Number of discriminators\n","num_d = 7\n","\n","# Parameter (Mean, Maximum, Minimum, Median)\n","parameter = \"Mean\"\n","\n","# Create discriminator models\n","d_model = []\n","for n_d in range(num_d):\n","     d_model.append(define_discriminator())\n","\n","# Create generator model\n","g_model = define_generator(latent_dim)\n","\n","# Create combined GAN model\n","gan_model = define_gan(g_model, d_model, num_d, parameter)\n","\n","# Load real images\n","dataset = load_real_samples()\n","\n","# Train the GAN\n","inicio = time.time()\n","train(g_model, d_model, num_d, gan_model, dataset, latent_dim, n_epochs, n_batch, parameter)\n","fin = time.time()\n","print(f'Training time: {fin - inicio} seconds')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Clean output"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","\n","# Remove files\n","def remove_files_with_extension(directory, extension):\n","    # Iterate over all files in the directory\n","    for filename in os.listdir(directory):\n","        # Check if the file has the specified extension\n","        if filename.endswith(extension):\n","            file_path = os.path.join(directory, filename)\n","            # Remove the file\n","            os.remove(file_path)\n","\n","# Specify the directory and extension\n","directory = \"/kaggle/working\"\n","extension = \".db\"\n","\n","# Call the function to remove files with the specified extension\n","remove_files_with_extension(directory, extension)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Generate images"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import Model\n","from keras.models import load_model\n","\n","# Load the model\n","model_saved = load_model('mod_Mean_7D_150.h5')\n","\n","# Generate latent points\n","latent_points, labels = generate_latent_points(100, 16)\n","\n","# Specify labels\n","labels = np.asarray([x for _ in range(4) for x in range(4)])\n","\n","# Generate images\n","X = model_saved.predict([latent_points, labels])\n","\n","# Scale the images\n","X = (X + 1) / 2.0"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Visualize some examples\n","grid_width = 4\n","grid_height = 4\n","fig, axes = plt.subplots(grid_width, grid_height)\n","fig.set_size_inches(8, 8)\n","\n","labels = ['glioma', 'meningioma', 'notumor', 'pituitary']\n","img_idx = 0\n","for i in range(grid_width):\n","    for j in range(grid_height):\n","        axes[i][j].axis('off')\n","        axes[i][j].set_title(labels[j])\n","        axes[i][j].imshow(X[img_idx])\n","        img_idx += 1\n","\n","plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.2, hspace=0.4)\n","\n","# Save the image file\n","plt.savefig(\"example.png\", bbox_inches=\"tight\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Fréchet Inception Distance (FID)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Calculate FID"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","from numpy import cov\n","from numpy import trace, sum\n","from scipy.linalg import sqrtm\n","from keras.applications.inception_v3 import InceptionV3, preprocess_input\n","from keras.datasets.mnist import load_data\n","from skimage.transform import resize\n","\n","# Scale the images\n","def scale_images(images, new_shape):\n","    images_list = [resize(image, new_shape, 0) for image in images]\n","    return np.asarray(images_list)\n","\n","# Calculate FID\n","def calculate_fid(model, images1, images2):\n","    act1 = model.predict(images1)\n","    act2 = model.predict(images2)\n","    mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n","    mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n","    ssdiff = sum((mu1 - mu2) ** 2.0)\n","    covmean = sqrtm(sigma1.dot(sigma2))\n","    if np.iscomplexobj(covmean):\n","        covmean = covmean.real\n","    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n","    return fid\n","\n","# Prepare InceptionV3 model (discriminator)\n","model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))\n","\n","# Parameters\n","n_packages = 100\n","n_classes = 4\n","num_images = n_packages * n_classes\n","\n","# Generate latent points\n","latent_points, labels = generate_latent_points(100, num_images, n_classes)\n","\n","# Labels\n","labels = np.asarray([x for _ in range(n_packages) for x in range(n_classes)])\n","\n","# Load the real dataset\n","dataset = load_real_samples()\n","n_samples = 400\n","[X_real, labels_real], y_real = generate_real_samples(dataset, n_samples)\n","X_real = X_real.astype('float32')\n","\n","# Scale the real images\n","X_real = scale_images(X_real, (299, 299, 3))\n","\n","# Preprocess the real images\n","X_real = preprocess_input(X_real)\n","\n","# FID for the selected models\n","fid_epoch = []\n","epoch = []\n","\n","for i in range(20):\n","    model_saved = 'mod_Mean_7D_%03d.h5' % ((i + 1) * 10)\n","    model_saved = load_model(model_saved)\n","    \n","    # Generate fake images\n","    X_fake = model_saved.predict([latent_points, labels])\n","    X_fake = X_fake.astype('float32')\n","    \n","    # Scale the fake images\n","    X_fake = scale_images(X_fake, (299, 299, 3))\n","    \n","    # Preprocess the fake images\n","    X_fake = preprocess_input(X_fake)\n","    \n","    # Calculate FID\n","    fid = calculate_fid(model, X_real, X_fake)\n","    fid_epoch.append(fid)\n","    epoch.append((i + 1) * 10)\n","    print('FID: %.3f' % fid)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Plot FID"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","x = epoch\n","y = fid_epoch\n","\n","# Create a new figure and axis\n","fig, ax = plt.subplots()\n","\n","# Plot the data points with diamond markers\n","ax.plot(x, y, marker='D')\n","\n","# Set labels and title\n","ax.set_xlabel('epoch')\n","ax.set_ylabel('fid')\n","ax.set_title('FID per Epoch')\n","\n","# Show the plot\n","plt.show()\n","\n","# Save the figure as an image file\n","#fig.savefig(\"FID.png\", bbox_inches='tight')\n","fig.savefig(\"FID 7D Mean 200E.png\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# FID\n","fid_epoch"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
